{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "_FwqKCL5bf99"
      ],
      "mount_file_id": "1ljcqFmP_YvVfEF3E1iDctBjfqxcc1CvA",
      "authorship_tag": "ABX9TyOk/3oJ0g7I/popZXZ+VrPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brancatellimat/speech-emotion-recognition/blob/main/DataAugmentation_FeatureExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "_FwqKCL5bf99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "\n",
        "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
        "import librosa\n",
        "import librosa.display\n",
        "import librosa.feature as libf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, minmax_scale, scale\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to play the audio files\n",
        "from IPython.display import Audio\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from scipy.stats import kurtosis\n",
        "from scipy.stats import skew\n",
        "\n",
        "eps = sys.float_info.epsilon\n",
        "\n",
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "vl-kMAUeNsqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if len(device_name) > 0:\n",
        "    print(\"Found GPU at: {}\".format(device_name))\n",
        "else:\n",
        "    device_name = \"/device:CPU:0\"\n",
        "    print(\"No GPU, using {}.\".format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwlX0dqrgOX0",
        "outputId": "967cd79a-7b43-4fc4-e0a5-be6260d58436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU, using /device:CPU:0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation\n",
        "In this work, we are going to generate more audio samples by adding noise and pitching the signal"
      ],
      "metadata": {
        "id": "MmTS3ZWXbkYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Audio Pattern Recognition/Project_Brancatelli/final_combined_dataset.csv')\n",
        "data_path.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7_bp6fuqJcRx",
        "outputId": "0c4bff39-b827-420a-cd40-8f7a72c466aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Emotions                                               Path\n",
              "0    angry  /content/drive/MyDrive/Colab Notebooks/Audio P...\n",
              "1  disgust  /content/drive/MyDrive/Colab Notebooks/Audio P...\n",
              "2  disgust  /content/drive/MyDrive/Colab Notebooks/Audio P...\n",
              "3    angry  /content/drive/MyDrive/Colab Notebooks/Audio P...\n",
              "4      sad  /content/drive/MyDrive/Colab Notebooks/Audio P..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecd14367-63ad-4f99-87b1-043959168653\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotions</th>\n",
              "      <th>Path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>angry</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Audio P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>disgust</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Audio P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>disgust</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Audio P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>angry</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Audio P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sad</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Audio P...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecd14367-63ad-4f99-87b1-043959168653')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ecd14367-63ad-4f99-87b1-043959168653 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ecd14367-63ad-4f99-87b1-043959168653');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3505ca29-b2c1-4af0-95e2-301ff4206e5f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3505ca29-b2c1-4af0-95e2-301ff4206e5f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3505ca29-b2c1-4af0-95e2-301ff4206e5f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOISE\n",
        "def noise(data):\n",
        "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
        "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "# PITCH\n",
        "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
        "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)"
      ],
      "metadata": {
        "id": "URRoUSOPb4HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract both Time and Frequency domain features"
      ],
      "metadata": {
        "id": "bv3h_YhP3A_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zcr(data,frame_length,hop_length):\n",
        "  with tf.device(device_name):\n",
        "    zcr=librosa.feature.zero_crossing_rate(y=data,frame_length=frame_length,hop_length=hop_length)\n",
        "    return np.squeeze(zcr)\n",
        "def rmse(data,frame_length=2048,hop_length=512):\n",
        "  with tf.device(device_name):\n",
        "    rmse=librosa.feature.rms(y=data,frame_length=frame_length,hop_length=hop_length)\n",
        "    return np.squeeze(rmse)\n",
        "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
        "  with tf.device(device_name):\n",
        "    mfcc=librosa.feature.mfcc(y=data,sr=sr)\n",
        "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)"
      ],
      "metadata": {
        "id": "ywoG8RTL3EYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
        "  with tf.device(device_name):\n",
        "    result=np.array([])\n",
        "\n",
        "    result=np.hstack((result,\n",
        "                      zcr(data,frame_length,hop_length),\n",
        "                      rmse(data,frame_length,hop_length),\n",
        "                      mfcc(data,sr,frame_length,hop_length)\n",
        "                     ))\n",
        "    return result"
      ],
      "metadata": {
        "id": "-16qpiB_3JQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(path,duration=2.5, offset=0.6):\n",
        "  with tf.device(device_name):\n",
        "\n",
        "    # Original Audio\n",
        "    data,sr=librosa.load(path,duration=duration,offset=offset)\n",
        "    aud=extract_features(data)\n",
        "    audio=np.array(aud)\n",
        "\n",
        "    # Noised Audio\n",
        "    noised_audio=noise(data)\n",
        "    aud2=extract_features(noised_audio)\n",
        "    audio=np.vstack((audio,aud2))\n",
        "\n",
        "    # Pitched Audio\n",
        "    pitched_audio=pitch(data,sr)\n",
        "    aud3=extract_features(pitched_audio)\n",
        "    audio=np.vstack((audio,aud3))\n",
        "\n",
        "    # Noised and Pitched Audio\n",
        "    pitched_audio1=pitch(data,sr)\n",
        "    pitched_noised_audio=noise(pitched_audio1)\n",
        "    aud4=extract_features(pitched_noised_audio)\n",
        "    audio=np.vstack((audio,aud4))\n",
        "\n",
        "    return audio"
      ],
      "metadata": {
        "id": "OsZPgK8r3N3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import Parallel, delayed\n",
        "import timeit\n",
        "\n",
        "with tf.device(device_name):\n",
        "  start = timeit.default_timer()\n",
        "  # Define a function to get features for a single audio file\n",
        "  def process_feature(path, emotion):\n",
        "      features = get_features(path)\n",
        "      X = []\n",
        "      Y = []\n",
        "      for ele in features:\n",
        "          X.append(ele)\n",
        "          # appending emotion 3 times as we have made 2 augmentation techniques on each audio file + the original audio file.\n",
        "          Y.append(emotion)\n",
        "      return X, Y\n",
        "\n",
        "  paths = data_path.Path\n",
        "  emotions = data_path.Emotions\n",
        "\n",
        "  # Run the loop in parallel\n",
        "  with tf.device(device_name):\n",
        "    results = Parallel(n_jobs=-1)(delayed(process_feature)(path, emotion) for (path, emotion) in zip(paths, emotions))\n",
        "\n",
        "  # Collect the results\n",
        "  X = []\n",
        "  Y = []\n",
        "  for result in results:\n",
        "      x, y = result\n",
        "      X.extend(x)\n",
        "      Y.extend(y)\n",
        "\n",
        "\n",
        "  stop = timeit.default_timer()\n",
        "\n",
        "  print('Time: ', stop - start)"
      ],
      "metadata": {
        "id": "RmVFWoax3WjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(Y), data_path.Path.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x1BDg-96ZTv",
        "outputId": "97982c6a-0b66-485b-a909-bbe2c795c295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1680, 1680, (420,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Emotions = pd.DataFrame(X)\n",
        "Emotions['Emotions'] = Y\n",
        "Emotions.head()"
      ],
      "metadata": {
        "id": "9NTIL7In67Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Emotions.to_csv('features.csv', index=False)"
      ],
      "metadata": {
        "id": "v1E67hDA-dqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.move('/content/features.csv', '/content/drive/MyDrive/Colab Notebooks/Audio Pattern Recognition/Project_Brancatelli/features.csv')"
      ],
      "metadata": {
        "id": "jD9DELm0_ZR_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}